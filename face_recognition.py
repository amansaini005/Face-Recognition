# -*- coding: utf-8 -*-
"""FACE  RECOGNITION.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KO6jl4WnP-K7Y9yD9NNf0qaoVjre4_Pd
"""

import cv2
import os
import numpy as np
import matplotlib.pyplot as plt
import random

from tensorflow.keras.models import Model
from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten
import tensorflow as tf

POS_PATH = os.path.join('data', 'positive')
NEG_PATH = os.path.join('data', 'negative')
ANC_PATH = os.path.join('data', 'anchor')

os.makedirs(POS_PATH)
os.makedirs(NEG_PATH)
os.makedirs(ANC_PATH)

anchor = tf.data.Dataset.list_files('/content/data/anchor' +'/*.jpg').take(200)
positive = tf.data.Dataset.list_files('/content/data/positive' +'/*.jpg').take(200)
negative = tf.data.Dataset.list_files('/content/data/negative' +'/*.jpg').take(200)

di = anchor.as_numpy_iterator()
di.next()

"""# **PreProcess Data**"""

def preprocess(file_path):
    img = tf.io.read_file(file_path)
    image1 = tf.io.decode_jpeg(img)
    image1 = tf.image.resize(image1, (100,100))
    image1 = image1/255.0
    return image1

IMAGE =preprocess(b'/content/data/anchor/2022-08-31-210725.jpg')

IMAGE.numpy().min()

plt.imshow(IMAGE)

positives = tf.data.Dataset.zip((anchor, positive, tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))
negatives = tf.data.Dataset.zip((anchor, negative, tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))
data = positives.concatenate(negatives)

sample = data.as_numpy_iterator()
example = sample.next()
example

"""## **Build Train and Test**"""

def preprocess_twin(input_img, validation_img, label):
    return(preprocess(input_img), preprocess(validation_img), label)

res =preprocess_twin(*example)
len(res)

# build dataloader pipeline
data = data.map(preprocess_twin)
data = data.cache()
data = data.shuffle(buffer_size = 1024)

data

sample = data.as_numpy_iterator()
len(sample.next())

samp = sample.next()
plt.imshow(samp[0])

plt.imshow(samp[1])

samp[2]

# training partition

train_data = data.take(round(len(data)*0.7))

train_data = train_data.batch(16)
train_data = train_data.prefetch(8)

# testing partition
test_data = data.skip(round(len(data)*.7))
test_data = test_data.take(round(len(data)*.7))
test_data = test_data.batch(16)
test_data = test_data.prefetch(8)

"""## **Model Building**"""

# Build Embedding layer
def make_embedding():
  input = Input(shape=(100,100,3), name ='Input_Image')

  #First block
  X = Conv2D(64,(10,10), activation = "relu")(input)
  X = MaxPooling2D(64,(2,2), padding = "same")(X)

  # second block
  Y = Conv2D(128,(7,7), activation= "relu")(X)
  Y = MaxPooling2D(64,(2,2), padding = "same")(Y)

  #third block
  Z = Conv2D(128,(7,7), activation= "relu")(Y)
  Z = MaxPooling2D(64,(2,2), padding = "same")(Z)

  # final embedding block
  Z = Conv2D(256,(4,4), activation= "relu")(Z)
  Z = Flatten()(Z)
  out = Dense(4096, activation = "sigmoid")(Z)

  return Model(inputs = [input], outputs = [out], name = "embedding")

embedding = make_embedding()

embedding.summary()

"""## **Build Distance layer**"""

# Siamese L1 Distance class
class L1Dist(Layer):
  def __init__(self, **kwargs):
    super().__init__()

  def call(self, input_embedding, validation_embedding):
    return tf.math.abs(input_embedding - validation_embedding)

def _siamese_model():

  # anchor image input
  input_image = Input(name ="input_img", shape = (100,100,3))

  # validation image
  validation_image = Input(name = "validation_img", shape = (100,100,3))

  # combine siamese distance
  siamese_layer = L1Dist()
  siamese_layer._name = "distance"
  distances = siamese_layer(embedding(input_image), embedding(validation_image))

  # classification layer
  classifier = Dense(1, activation = "sigmoid")(distances)

  return Model(inputs = [input_image, validation_image], outputs = classifier, name = "Siamese_Network")

sia_model = _siamese_model()

sia_model.summary()

"""## **Training model**"""

# setup loss and optimizer
binary_cross_loss = tf.losses.BinaryCrossentropy()

opt =tf.keras.optimizers.Adam(1e-4)

# Establish Checkpoints
checkpoint_dir = "/content/training_checkpoint"
checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')
checkpoint = tf.train.Checkpoint(opt = opt, siamese_model = sia_model)

# build train step function
@tf.function
def train_step(batch):
  
  with tf.GradientTape() as tape:

    x = batch[:2]

    y = batch[2]

    yhat = sia_model(x, training =True)

    loss = binary_cross_loss(y, yhat)
  print(loss)  

  grad = tape.gradient(loss, sia_model.trainable_variables)

  opt.apply_gradients(zip(grad, sia_model.trainable_variables))
  return loss

# building training loop
def train(data, EPOCHS):
  for epoch in range(1, EPOCHS+1):
    print('\n Epoch {}/{}'.format(epoch, EPOCHS))
    progbar = tf.keras.utils.Progbar(len(data))

    # loop through each batch
    for idx, batch in enumerate(data):
      train_step(batch)
      progbar.update(idx+1)

     # save checkpoints
    if epoch % 10 == 0:
      checkpoint.save(file_prefix = checkpoint_prefix)

EPOCHS = 50
train(train_data, EPOCHS)

## Evaluation 
from tensorflow.keras.metrics import Precision, Recall

test_input, test_val, y_true = test_data.as_numpy_iterator().next()

"""# **Predictions**"""

y_hat = sia_model.predict([test_input, test_val])
y_hat

# post processing results
[1 if prediction > 0.5 else 0 for prediction in y_hat]

y_true

# creatind metric object
m = Recall()
# calculate recall value
m.update_state(y_true, y_hat)

# return results
m.result().numpy()

# creatind metric object
m = Precision()
# calculate precision value
m.update_state(y_true, y_hat)

# return results
m.result().numpy()

"""# **EXAMPLES**"""

plt.figure(figsize = (10,8))
plt.subplot(1,2,1)
plt.imshow(test_input[0])
plt.subplot(1,2,2)
plt.imshow(test_val[0])
plt.show()

## Save model
sia_model.save('face_recognition.h5')

!echo "# Face-Recognition" >> README.md
!git init

!git add README.md

!git commit -m "first commit"
!git branch -M main

!git config  --global user.email "amaner24@gmail.com.com"

!git config --global user.name "amansaini005"

!git commit -m "first commit"
!git branch -M main

